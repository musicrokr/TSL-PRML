{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger\n",
    "from keras.layers import Activation, Conv1D, Dense, Embedding, Flatten, Input, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.datasets.base import get_data_home\n",
    "from keras.metrics import categorical_accuracy\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.0.0-rc1\n",
      "  Using cached https://files.pythonhosted.org/packages/0a/f0/020664b2286eb78b5ff16aad0fa1b96483be525a937d4bf6e168232853e2/tensorflow-2.0.0rc1-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-rc1) (0.7.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-rc1) (1.0.8)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-rc1) (0.1.7)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-rc1) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-rc1) (3.0.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-rc1) (1.11.2)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-rc1) (0.2.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-rc1) (0.8.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-rc1) (0.33.4)\n",
      "Collecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 (from tensorflow==2.0.0-rc1)\n",
      "  Using cached https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-rc1) (1.12.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-rc1) (1.16.1)\n",
      "Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806 (from tensorflow==2.0.0-rc1)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-rc1) (1.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-rc1) (1.16.4)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-rc1) (3.8.0)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow==2.0.0-rc1) (2.9.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc1) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc1) (0.15.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc1) (41.0.1)\n",
      "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow\n",
      "Successfully installed tb-nightly-1.15.0a20190806 tensorflow-2.0.0rc1 tf-estimator-nightly-1.14.0.dev2019080601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\darry\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\darry\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install --user tensorflow==2.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processed Data Frame [ Do Not Use this, Use the Training, Tesing and Validation Data Sets Instead]\n",
    "data_path = \"./Pickles/all_articles_processed.pickle\"\n",
    "with open(data_path, 'rb') as data:\n",
    "    all_articles = pickle.load(data)\n",
    "    \n",
    "    \n",
    "#TD-IDF Features    \n",
    "#Training Features\n",
    "training_features_path = \"./Pickles/tdidf_training_features.pickle\"\n",
    "with open(training_features_path, 'rb') as data:\n",
    "    tdidf_training_features = pickle.load(data)\n",
    "    \n",
    "#Training Labels\n",
    "training_labels_path = \"./Pickles/tdidf_training_labels.pickle\"\n",
    "with open(training_labels_path, 'rb') as data:\n",
    "    tdidf_training_labels = pickle.load(data)\n",
    "    \n",
    "#Test Features\n",
    "test_features_path = \"./Pickles/tdidf_test_features.pickle\"\n",
    "with open(test_features_path, 'rb') as data:\n",
    "    tdidf_test_features = pickle.load(data)\n",
    "    \n",
    "#Test Labels\n",
    "test_labels_path = \"./Pickles/tdidf_test_labels.pickle\"\n",
    "with open(test_labels_path, 'rb') as data:\n",
    "    tdidf_test_labels = pickle.load(data)\n",
    "    \n",
    "#Validation Features\n",
    "test_features_path = \"./Pickles/tdidf_validation_features.pickle\"\n",
    "with open(test_features_path, 'rb') as data:\n",
    "    tdidf_validation_features = pickle.load(data)\n",
    "    \n",
    "#Validation Labels\n",
    "test_labels_path = \"./Pickles/tdidf_validation_labels.pickle\"\n",
    "with open(test_labels_path, 'rb') as data:\n",
    "    tdidf_validation_labels = pickle.load(data)\n",
    "    \n",
    "    \n",
    "#Sequence Vector Features    \n",
    "#Training Features\n",
    "training_features_path = \"./Pickles/sv_training_features.pickle\"\n",
    "with open(training_features_path, 'rb') as data:\n",
    "    sv_training_features = pickle.load(data)\n",
    "    \n",
    "#Training Labels\n",
    "training_labels_path = \"./Pickles/sv_training_labels.pickle\"\n",
    "with open(training_labels_path, 'rb') as data:\n",
    "    sv_training_labels = pickle.load(data)\n",
    "    \n",
    "#Test Features\n",
    "test_features_path = \"./Pickles/sv_test_features.pickle\"\n",
    "with open(test_features_path, 'rb') as data:\n",
    "    sv_test_features = pickle.load(data)\n",
    "    \n",
    "#Test Labels\n",
    "test_labels_path = \"./Pickles/sv_test_labels.pickle\"\n",
    "with open(test_labels_path, 'rb') as data:\n",
    "    sv_test_labels = pickle.load(data)\n",
    "    \n",
    "#Validation Features\n",
    "test_features_path = \"./Pickles/sv_validation_features.pickle\"\n",
    "with open(test_features_path, 'rb') as data:\n",
    "    sv_validation_features = pickle.load(data)\n",
    "    \n",
    "#Validation Labels\n",
    "test_labels_path = \"./Pickles/sv_validation_labels.pickle\"\n",
    "with open(test_labels_path, 'rb') as data:\n",
    "    sv_validation_labels = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_articles\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['article'] #Extract text\n",
    "target = df['category'] # Extract target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (target[:10])\n",
    "\n",
    "print (len(texts))\n",
    "print (len(target))\n",
    "#print (len(texts[0].split()))\n",
    "print (texts[0])\n",
    "print (target[0])\n",
    "print (df['category'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 20000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size) # Setup tokenizer\n",
    "tokenizer.fit_on_texts(df['article'])\n",
    "sequences = tokenizer.texts_to_sequences(df['article']) # Generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (tokenizer.texts_to_sequences(['Hello King, how are you?']))\n",
    "\n",
    "print (len(sequences))\n",
    "print (len(sequences[0]))\n",
    "print (sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found {:,} unique words.'.format(len(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inverse index mapping numbers to words\n",
    "inv_index = {v: k for k, v in tokenizer.word_index.items()}\n",
    "\n",
    "# Print out text again\n",
    "for w in sequences[0]:\n",
    "    x = inv_index.get(w)\n",
    "    print(x,end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average length of a text\n",
    "avg = sum(map(len, sequences)) / len(sequences)\n",
    "\n",
    "# Get the standard deviation of the sequence length\n",
    "std = np.sqrt(sum(map(lambda x: (len(x) - avg)**2, sequences)) / len(sequences))\n",
    "\n",
    "avg,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pad_sequences([[1,2,3]], maxlen=5))\n",
    "print(pad_sequences([[1,2,3,4,5,6]], maxlen=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 100\n",
    "data = pad_sequences(sequences, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "labels = to_categorical(np.asarray(df['category_code']))\n",
    "print('Shape of data:', data.shape)\n",
    "print('Shape of labels:', labels.shape)\n",
    "\n",
    "print (df['category_code'][0])\n",
    "print (labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dir = './Glove' # This is the folder with the dataset\n",
    "\n",
    "embeddings_index = {} # We create a dictionary of word -> embedding\n",
    "\n",
    "with open(os.path.join(glove_dir, 'glove.6B.100d.txt'), encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0] # The first value is the word, the rest are the values of the embedding\n",
    "        embedding = np.asarray(values[1:], dtype='float32') # Load embedding\n",
    "        embeddings_index[word] = embedding # Add embedding to our embedding dictionary\n",
    "\n",
    "print('Found {:,} word vectors in GloVe.'.format(len(embeddings_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (embeddings_index['frog'])\n",
    "print (len(embeddings_index['frog']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.linalg.norm(embeddings_index['man'] - embeddings_index['woman']))\n",
    "print (np.linalg.norm(embeddings_index['man'] - embeddings_index['cat']))\n",
    "\n",
    "# https://nlp.stanford.edu/projects/glove/\n",
    "print (np.linalg.norm(embeddings_index['frog'] - embeddings_index['toad']))\n",
    "print (np.linalg.norm(embeddings_index['frog'] - embeddings_index['man']))\n",
    "\n",
    "print (np.linalg.norm(embeddings_index['frog'] - embeddings_index['fog']))\n",
    "\n",
    "print (np.linalg.norm(embeddings_index['frog'] - embeddings_index['fork']))\n",
    "print (np.linalg.norm(embeddings_index['frog'] - embeddings_index['skyscraper']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100 # We use 100 dimensional glove vectors\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(vocab_size, len(word_index)) # How many words are there actually\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, embedding_dim))\n",
    "\n",
    "# The vectors need to be in the same position as their index. \n",
    "# Meaning a word with token 1 needs to be in the second row (rows start with zero) and so on\n",
    "\n",
    "# Loop over all words in the word index\n",
    "for word, i in word_index.items():\n",
    "    # If we are above the amount of words we want to use we do nothing\n",
    "    if i >= vocab_size: \n",
    "        continue\n",
    "    # Get the embedding vector for the word\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    # If there is an embedding vector, put it in the embedding matrix\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (embedding_matrix[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, \n",
    "                        embedding_dim, \n",
    "                        input_length=max_length, \n",
    "                        weights = [embedding_matrix], \n",
    "                        trainable = False))\n",
    "    model.add(Conv1D(128, 3, activation='relu'))\n",
    "    model.add(MaxPooling1D(3))\n",
    "    model.add(Conv1D(128, 3, activation='relu'))\n",
    "    model.add(MaxPooling1D(3))\n",
    "    model.add(Conv1D(128, 3, activation='relu'))\n",
    "    model.add(MaxPooling1D(3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=['accuracy'])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the models\n",
    "model       = createModel() # This is meant for training\n",
    "modelGo     = createModel() # This is used for final testing\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname   = 'deeplearning_glove'\n",
    "filepath        = './Models/'+modelname + \".hdf5\"\n",
    "checkpoint      = ModelCheckpoint(filepath, \n",
    "                                  monitor='val_acc', \n",
    "                                  verbose=0, \n",
    "                                  save_best_only=True, \n",
    "                                  mode='max')\n",
    "\n",
    "                            # Log the epoch detail into csv\n",
    "csv_logger      = CSVLogger('./Models/'+modelname +'.csv')\n",
    "callbacks_list  = [checkpoint,csv_logger]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trDat, tsDat, trLbl, tsLbl = train_test_split(data, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss='binary_crossentropy',  # https://stackoverflow.com/questions/42081257/keras-binary-crossentropy-vs-categorical-crossentropy-performance\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# https://stackoverflow.com/questions/42081257/keras-binary-crossentropy-vs-categorical-crossentropy-performance\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#model.fit(data, labels, validation_split=0.2, epochs=10)\n",
    "\n",
    "\n",
    "model.fit(trDat, \n",
    "          trLbl, \n",
    "          validation_data=(tsDat, tsLbl), \n",
    "          epochs=10, \n",
    "          batch_size=128,\n",
    "          shuffle=True,\n",
    "          callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts    = modelGo.predict(tsDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predout     = np.argmax(predicts,axis=1)\n",
    "testout     = np.argmax(tsLbl,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelname   = ['Singapore', 'Sport', 'Lifestyle', 'World', 'Business', 'Tech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testScores  = metrics.accuracy_score(testout,predout)\n",
    "confusion   = metrics.confusion_matrix(testout,predout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best accuracy (on testing dataset): %.2f%%\" % (testScores*100))\n",
    "print(metrics.classification_report(testout,predout,target_names=labelname,digits=4))\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "records     = pd.read_csv('./Models/'+modelname +'.csv')\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(records['val_loss'])\n",
    "plt.plot(records['loss'])\n",
    "plt.yticks([0,0.20,0.40,0.60,0.80,1.00])\n",
    "plt.title('Loss value',fontsize=12)\n",
    "\n",
    "ax          = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(records['val_acc'])\n",
    "plt.plot(records['acc'])\n",
    "plt.yticks([0.6,0.7,0.8,0.9,1.0])\n",
    "plt.title('Accuracy',fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = data[400] # get the tokens\n",
    "print (df['article'][400])\n",
    "\n",
    "# Print tokens as text\n",
    "for w in example:\n",
    "    x = inv_index.get(w)\n",
    "    print(x,end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction\n",
    "pred = model.predict(example.reshape(1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output predicted category\n",
    "df['category'][np.argmax(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Models/decisionTree_best_model.pickle', 'wb') as output:\n",
    "    pickle.dump(best_lrc, output)\n",
    "    \n",
    "with open('Models/decisionTree_best_model_details.pickle', 'wb') as output:\n",
    "    pickle.dump(df_models_lrc, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

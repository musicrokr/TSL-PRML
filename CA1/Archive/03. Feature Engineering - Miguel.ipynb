{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create features from the raw text so we can train the machine learning models. The steps followed are:\n",
    "\n",
    "1. **Text Cleaning and Preparation**: cleaning of special characters, downcasing, punctuation signs. possessive pronouns and stop words removal and lemmatization. \n",
    "2. **Label coding**: creation of a dictionary to map each category to a code.\n",
    "3. **Train-test split**: to test the models on unseen data.\n",
    "4. **Text representation**: use of TF-IDF scores to represent text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we'll load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = \"./Pickles/all_articles_processed.pickle\"\n",
    "\n",
    "with open(path_df, 'rb') as data:\n",
    "    df = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "      <th>category_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Straits Times</td>\n",
       "      <td>Sales for Handmaid's Tale sequel top 125,000 c...</td>\n",
       "      <td>new york ap  sales margaret atwoods testament...</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Straits Times</td>\n",
       "      <td>R. Kelly a no-show in court on Minnesota solic...</td>\n",
       "      <td>minneapolis ap  singer r kelly noshow initial...</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Straits Times</td>\n",
       "      <td>HK director Derek Tsang picks forest in Japan ...</td>\n",
       "      <td>soul mate director derek tsang  know ask team...</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Straits Times</td>\n",
       "      <td>Tony Hadley, ex-frontman of Spandau Ballet, to...</td>\n",
       "      <td>singapore  voice behind spandau ballet hit tr...</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The Straits Times</td>\n",
       "      <td>South Korean actor Sung Hoon holding meet-and-...</td>\n",
       "      <td>singapore  south korean heartthrob sing hoon ...</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index             source  \\\n",
       "0      0  The Straits Times   \n",
       "1      1  The Straits Times   \n",
       "2      2  The Straits Times   \n",
       "3      3  The Straits Times   \n",
       "4      4  The Straits Times   \n",
       "\n",
       "                                               title  \\\n",
       "0  Sales for Handmaid's Tale sequel top 125,000 c...   \n",
       "1  R. Kelly a no-show in court on Minnesota solic...   \n",
       "2  HK director Derek Tsang picks forest in Japan ...   \n",
       "3  Tony Hadley, ex-frontman of Spandau Ballet, to...   \n",
       "4  South Korean actor Sung Hoon holding meet-and-...   \n",
       "\n",
       "                                             Content   Category  category_code  \n",
       "0   new york ap  sales margaret atwoods testament...  Lifestyle              3  \n",
       "1   minneapolis ap  singer r kelly noshow initial...  Lifestyle              3  \n",
       "2   soul mate director derek tsang  know ask team...  Lifestyle              3  \n",
       "3   singapore  voice behind spandau ballet hit tr...  Lifestyle              3  \n",
       "4   singapore  south korean heartthrob sing hoon ...  Lifestyle              3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'article': 'Content','category':'Category'})\n",
    "df= df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index', 'source', 'title', 'Content', 'Category', 'category_code']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And visualize one sample news content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' minneapolis ap  singer r kelly noshow initial court appearance minnesota case accuse offer yearold girl us take clothe dance  kelly jail chicago sexual abuse count charge minnesota august solicit girl meet concert minneapolis kelly whose full name robert sylvester kelly face previously file federal state charge new york chicago     prosecutor judith cole tell judge jay quam thursdays sept  brief hear federal authorities illinois give us access case resolve judge issue bench warrant formality kellys attorney steve greenberg didnt attend hear isnt officially register minnesota case say never get notice       spokesman county attorneys office say summon send kellys last know address '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]['Content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text cleaning and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Special character cleaning\n",
    "\n",
    "We can see the following special characters:\n",
    "\n",
    "* ``\\r``\n",
    "* ``\\n``\n",
    "* ``\\`` before possessive pronouns (`government's = government\\'s`)\n",
    "* ``\\`` before possessive pronouns 2 (`Yukos'` = `Yukos\\'`)\n",
    "* ``\"`` when quoting text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\r and \\n\n",
    "df['Content_Parsed_1'] = df['Content'].str.replace(\"\\r\", \" \")\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"\\n\", \" \")\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"    \", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding 3rd and 4th bullet, although it seems there is a special character, it won't affect us since it is not a *real* character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mr Greenspan's\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Mr Greenspan\\'s\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \" when quoting text\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace('\"', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Upcase/downcase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll downcase the texts because we want, for example, `Football` and `football` to be the same word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing the text\n",
    "df['Content_Parsed_2'] = df['Content_Parsed_1'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Punctuation signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Punctuation signs won't have any predicting power, so we'll just get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_signs = list(\"?:!.,;\")\n",
    "df['Content_Parsed_3'] = df['Content_Parsed_2']\n",
    "\n",
    "for punct_sign in punctuation_signs:\n",
    "    df['Content_Parsed_3'] = df['Content_Parsed_3'].str.replace(punct_sign, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By doing this we are messing up with some numbers, but it's no problem since we aren't expecting any predicting power from them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Possessive pronouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also remove possessive pronoun terminations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_4'] = df['Content_Parsed_3'].str.replace(\"'s\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Stemming and Lemmatization\n",
    "\n",
    "Since stemming can produce output words that don't exist, we'll only use a lemmatization process at this moment. Lemmatization takes into consideration the morphological analysis of the words and returns words that do exist, so it will be more useful for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\darry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\darry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading punkt and wordnet from NLTK\n",
    "nltk.download('punkt')\n",
    "print(\"------------------------------------------------------------\")\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the lemmatizer into an object\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to lemmatize, we have to iterate through every word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = len(df)\n",
    "lemmatized_text_list = []\n",
    "\n",
    "for row in range(0, nrows):\n",
    "    \n",
    "    # Create an empty list containing lemmatized words\n",
    "    lemmatized_list = []\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text = df.loc[row]['Content_Parsed_4']\n",
    "    text_words = text.split(\" \")\n",
    "\n",
    "    # Iterate through every word to lemmatize\n",
    "    for word in text_words:\n",
    "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        \n",
    "    # Join the list\n",
    "    lemmatized_text = \" \".join(lemmatized_list)\n",
    "    \n",
    "    # Append to the list containing the texts\n",
    "    lemmatized_text_list.append(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_5'] = lemmatized_text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although lemmatization doesn't work perfectly in all cases (as can be seen in the example below), it can be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\darry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the stop words list\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the stop words in english\n",
    "stop_words = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove the stop words, we'll handle a regular expression only detecting whole words, as seen in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'StopWord eating a meal'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"me eating a meal\"\n",
    "word = \"me\"\n",
    "\n",
    "# The regular expression is:\n",
    "regex = r\"\\b\" + word + r\"\\b\"  # we need to build it like that to work properly\n",
    "\n",
    "re.sub(regex, \"StopWord\", example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now loop through all the stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_6'] = df['Content_Parsed_5']\n",
    "\n",
    "for stop_word in stop_words:\n",
    "\n",
    "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "    df['Content_Parsed_6'] = df['Content_Parsed_6'].str.replace(regex_stopword, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some dobule/triple spaces between words because of the replacements. However, it's not a problem because we'll tokenize by the spaces later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we'll show an original news article and its modifications throughout the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' jacqueline wong kenneth reconcile since catch kiss singer andy hui taxi april career front reason happy inadvertently benefit current tense situation hong kong wongs show put cold storage employer tvb scandal break     hong kong face demonstrations broadcaster careful screen show depict police triads link assault prodemocracy supporters yuen long mtr station july still show must go tvb reportedly reshuffle program include tap show feature wong come news show find voice slat primetime air oct       ask wong would return unite state  flee scandal  promote show producer tell oriental daily news tvb tell could  \\xa0        relate story jacqueline wong set early comeback tvb put hold show police triads     \\xa0   relate story fan urge kenneth date actress natalie tong breakup jacqueline wong     \\xa0   relate story kenneth longer consider jacqueline wong girlfriend friends    could contact get reply wong send text message inform find voice receive rollout clearance meanwhile tap star sequel hit tvb drama want baby original show feature ali lee lai lok yi main roles lee drop sequel supposedly prodemocracy view tvb apparently decide make sense lai pair eliza sam lees replacement hence lai drop rope lai say understand new cast decisions say one us miss sequel wouldnt use new cast right thing would say diplomatically employer give new work duty   \\xa0   relate stories\\xa0         relate story haters feel better vent anger let say jacqueline wongs sister scarlett          relate story jacqueline wong set early comeback tvb put hold show police triads          relate story andy hui leave photos sammi cheng celebrities          relate story sammi cheng andy hui spot hold hand britain          relate story sammi cheng take holiday pal hubby andy hui finish  show hk          relate story sammi cheng include andy hui selfie move divide fan          relate story andy hui boo sammi cheng kick concert          relate story jacqueline wongs appearance tvb talk show spark comeback talk          relate story tvb actress jacqueline wong ask actor kenneth spend time america       '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Special character cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' jacqueline wong kenneth reconcile since catch kiss singer andy hui taxi april career front reason happy inadvertently benefit current tense situation hong kong wongs show put cold storage employer tvb scandal break  hong kong face demonstrations broadcaster careful screen show depict police triads link assault prodemocracy supporters yuen long mtr station july still show must go tvb reportedly reshuffle program include tap show feature wong come news show find voice slat primetime air oct    ask wong would return unite state  flee scandal  promote show producer tell oriental daily news tvb tell could  \\xa0  relate story jacqueline wong set early comeback tvb put hold show police triads  \\xa0   relate story fan urge kenneth date actress natalie tong breakup jacqueline wong  \\xa0   relate story kenneth longer consider jacqueline wong girlfriend friends could contact get reply wong send text message inform find voice receive rollout clearance meanwhile tap star sequel hit tvb drama want baby original show feature ali lee lai lok yi main roles lee drop sequel supposedly prodemocracy view tvb apparently decide make sense lai pair eliza sam lees replacement hence lai drop rope lai say understand new cast decisions say one us miss sequel wouldnt use new cast right thing would say diplomatically employer give new work duty   \\xa0   relate stories\\xa0   relate story haters feel better vent anger let say jacqueline wongs sister scarlett    relate story jacqueline wong set early comeback tvb put hold show police triads    relate story andy hui leave photos sammi cheng celebrities    relate story sammi cheng andy hui spot hold hand britain    relate story sammi cheng take holiday pal hubby andy hui finish  show hk    relate story sammi cheng include andy hui selfie move divide fan    relate story andy hui boo sammi cheng kick concert    relate story jacqueline wongs appearance tvb talk show spark comeback talk    relate story tvb actress jacqueline wong ask actor kenneth spend time america    '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Upcase/downcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' jacqueline wong kenneth reconcile since catch kiss singer andy hui taxi april career front reason happy inadvertently benefit current tense situation hong kong wongs show put cold storage employer tvb scandal break  hong kong face demonstrations broadcaster careful screen show depict police triads link assault prodemocracy supporters yuen long mtr station july still show must go tvb reportedly reshuffle program include tap show feature wong come news show find voice slat primetime air oct    ask wong would return unite state  flee scandal  promote show producer tell oriental daily news tvb tell could  \\xa0  relate story jacqueline wong set early comeback tvb put hold show police triads  \\xa0   relate story fan urge kenneth date actress natalie tong breakup jacqueline wong  \\xa0   relate story kenneth longer consider jacqueline wong girlfriend friends could contact get reply wong send text message inform find voice receive rollout clearance meanwhile tap star sequel hit tvb drama want baby original show feature ali lee lai lok yi main roles lee drop sequel supposedly prodemocracy view tvb apparently decide make sense lai pair eliza sam lees replacement hence lai drop rope lai say understand new cast decisions say one us miss sequel wouldnt use new cast right thing would say diplomatically employer give new work duty   \\xa0   relate stories\\xa0   relate story haters feel better vent anger let say jacqueline wongs sister scarlett    relate story jacqueline wong set early comeback tvb put hold show police triads    relate story andy hui leave photos sammi cheng celebrities    relate story sammi cheng andy hui spot hold hand britain    relate story sammi cheng take holiday pal hubby andy hui finish  show hk    relate story sammi cheng include andy hui selfie move divide fan    relate story andy hui boo sammi cheng kick concert    relate story jacqueline wongs appearance tvb talk show spark comeback talk    relate story tvb actress jacqueline wong ask actor kenneth spend time america    '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Punctuation signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' jacqueline wong kenneth reconcile since catch kiss singer andy hui taxi april career front reason happy inadvertently benefit current tense situation hong kong wongs show put cold storage employer tvb scandal break  hong kong face demonstrations broadcaster careful screen show depict police triads link assault prodemocracy supporters yuen long mtr station july still show must go tvb reportedly reshuffle program include tap show feature wong come news show find voice slat primetime air oct    ask wong would return unite state  flee scandal  promote show producer tell oriental daily news tvb tell could  \\xa0  relate story jacqueline wong set early comeback tvb put hold show police triads  \\xa0   relate story fan urge kenneth date actress natalie tong breakup jacqueline wong  \\xa0   relate story kenneth longer consider jacqueline wong girlfriend friends could contact get reply wong send text message inform find voice receive rollout clearance meanwhile tap star sequel hit tvb drama want baby original show feature ali lee lai lok yi main roles lee drop sequel supposedly prodemocracy view tvb apparently decide make sense lai pair eliza sam lees replacement hence lai drop rope lai say understand new cast decisions say one us miss sequel wouldnt use new cast right thing would say diplomatically employer give new work duty   \\xa0   relate stories\\xa0   relate story haters feel better vent anger let say jacqueline wongs sister scarlett    relate story jacqueline wong set early comeback tvb put hold show police triads    relate story andy hui leave photos sammi cheng celebrities    relate story sammi cheng andy hui spot hold hand britain    relate story sammi cheng take holiday pal hubby andy hui finish  show hk    relate story sammi cheng include andy hui selfie move divide fan    relate story andy hui boo sammi cheng kick concert    relate story jacqueline wongs appearance tvb talk show spark comeback talk    relate story tvb actress jacqueline wong ask actor kenneth spend time america    '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Possessive pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' jacqueline wong kenneth reconcile since catch kiss singer andy hui taxi april career front reason happy inadvertently benefit current tense situation hong kong wongs show put cold storage employer tvb scandal break  hong kong face demonstrations broadcaster careful screen show depict police triads link assault prodemocracy supporters yuen long mtr station july still show must go tvb reportedly reshuffle program include tap show feature wong come news show find voice slat primetime air oct    ask wong would return unite state  flee scandal  promote show producer tell oriental daily news tvb tell could  \\xa0  relate story jacqueline wong set early comeback tvb put hold show police triads  \\xa0   relate story fan urge kenneth date actress natalie tong breakup jacqueline wong  \\xa0   relate story kenneth longer consider jacqueline wong girlfriend friends could contact get reply wong send text message inform find voice receive rollout clearance meanwhile tap star sequel hit tvb drama want baby original show feature ali lee lai lok yi main roles lee drop sequel supposedly prodemocracy view tvb apparently decide make sense lai pair eliza sam lees replacement hence lai drop rope lai say understand new cast decisions say one us miss sequel wouldnt use new cast right thing would say diplomatically employer give new work duty   \\xa0   relate stories\\xa0   relate story haters feel better vent anger let say jacqueline wongs sister scarlett    relate story jacqueline wong set early comeback tvb put hold show police triads    relate story andy hui leave photos sammi cheng celebrities    relate story sammi cheng andy hui spot hold hand britain    relate story sammi cheng take holiday pal hubby andy hui finish  show hk    relate story sammi cheng include andy hui selfie move divide fan    relate story andy hui boo sammi cheng kick concert    relate story jacqueline wongs appearance tvb talk show spark comeback talk    relate story tvb actress jacqueline wong ask actor kenneth spend time america    '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' jacqueline wong kenneth reconcile since catch kiss singer andy hui taxi april career front reason happy inadvertently benefit current tense situation hong kong wongs show put cold storage employer tvb scandal break  hong kong face demonstrations broadcaster careful screen show depict police triads link assault prodemocracy supporters yuen long mtr station july still show must go tvb reportedly reshuffle program include tap show feature wong come news show find voice slat primetime air oct    ask wong would return unite state  flee scandal  promote show producer tell oriental daily news tvb tell could  \\xa0  relate story jacqueline wong set early comeback tvb put hold show police triads  \\xa0   relate story fan urge kenneth date actress natalie tong breakup jacqueline wong  \\xa0   relate story kenneth longer consider jacqueline wong girlfriend friends could contact get reply wong send text message inform find voice receive rollout clearance meanwhile tap star sequel hit tvb drama want baby original show feature ali lee lai lok yi main roles lee drop sequel supposedly prodemocracy view tvb apparently decide make sense lai pair eliza sam lees replacement hence lai drop rope lai say understand new cast decisions say one us miss sequel wouldnt use new cast right thing would say diplomatically employer give new work duty   \\xa0   relate stories\\xa0   relate story haters feel better vent anger let say jacqueline wongs sister scarlett    relate story jacqueline wong set early comeback tvb put hold show police triads    relate story andy hui leave photos sammi cheng celebrities    relate story sammi cheng andy hui spot hold hand britain    relate story sammi cheng take holiday pal hubby andy hui finish  show hk    relate story sammi cheng include andy hui selfie move divide fan    relate story andy hui boo sammi cheng kick concert    relate story jacqueline wongs appearance tvb talk show spark comeback talk    relate story tvb actress jacqueline wong ask actor kenneth spend time america    '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' jacqueline wong kenneth reconcile since catch kiss singer andy hui taxi april career front reason happy inadvertently benefit current tense situation hong kong wongs show put cold storage employer tvb scandal break  hong kong face demonstrations broadcaster careful screen show depict police triads link assault prodemocracy supporters yuen long mtr station july still show must go tvb reportedly reshuffle program include tap show feature wong come news show find voice slat primetime air oct    ask wong would return unite state  flee scandal  promote show producer tell oriental daily news tvb tell could  \\xa0  relate story jacqueline wong set early comeback tvb put hold show police triads  \\xa0   relate story fan urge kenneth date actress natalie tong breakup jacqueline wong  \\xa0   relate story kenneth longer consider jacqueline wong girlfriend friends could contact get reply wong send text message inform find voice receive rollout clearance meanwhile tap star sequel hit tvb drama want baby original show feature ali lee lai lok yi main roles lee drop sequel supposedly prodemocracy view tvb apparently decide make sense lai pair eliza sam lees replacement hence lai drop rope lai say understand new cast decisions say one us miss sequel wouldnt use new cast right thing would say diplomatically employer give new work duty   \\xa0   relate stories\\xa0   relate story haters feel better vent anger let say jacqueline wongs sister scarlett    relate story jacqueline wong set early comeback tvb put hold show police triads    relate story andy hui leave photos sammi cheng celebrities    relate story sammi cheng andy hui spot hold hand britain    relate story sammi cheng take holiday pal hubby andy hui finish  show hk    relate story sammi cheng include andy hui selfie move divide fan    relate story andy hui boo sammi cheng kick concert    relate story jacqueline wongs appearance tvb talk show spark comeback talk    relate story tvb actress jacqueline wong ask actor kenneth spend time america    '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can delete the intermediate columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "      <th>category_code</th>\n",
       "      <th>Content_Parsed_1</th>\n",
       "      <th>Content_Parsed_2</th>\n",
       "      <th>Content_Parsed_3</th>\n",
       "      <th>Content_Parsed_4</th>\n",
       "      <th>Content_Parsed_5</th>\n",
       "      <th>Content_Parsed_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Straits Times</td>\n",
       "      <td>Sales for Handmaid's Tale sequel top 125,000 c...</td>\n",
       "      <td>new york ap  sales margaret atwoods testament...</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>3</td>\n",
       "      <td>new york ap  sales margaret atwoods testament...</td>\n",
       "      <td>new york ap  sales margaret atwoods testament...</td>\n",
       "      <td>new york ap  sales margaret atwoods testament...</td>\n",
       "      <td>new york ap  sales margaret atwoods testament...</td>\n",
       "      <td>new york ap  sales margaret atwoods testament...</td>\n",
       "      <td>new york ap  sales margaret atwoods testament...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index             source  \\\n",
       "0      0  The Straits Times   \n",
       "\n",
       "                                               title  \\\n",
       "0  Sales for Handmaid's Tale sequel top 125,000 c...   \n",
       "\n",
       "                                             Content   Category  \\\n",
       "0   new york ap  sales margaret atwoods testament...  Lifestyle   \n",
       "\n",
       "   category_code                                   Content_Parsed_1  \\\n",
       "0              3   new york ap  sales margaret atwoods testament...   \n",
       "\n",
       "                                    Content_Parsed_2  \\\n",
       "0   new york ap  sales margaret atwoods testament...   \n",
       "\n",
       "                                    Content_Parsed_3  \\\n",
       "0   new york ap  sales margaret atwoods testament...   \n",
       "\n",
       "                                    Content_Parsed_4  \\\n",
       "0   new york ap  sales margaret atwoods testament...   \n",
       "\n",
       "                                    Content_Parsed_5  \\\n",
       "0   new york ap  sales margaret atwoods testament...   \n",
       "\n",
       "                                    Content_Parsed_6  \n",
       "0   new york ap  sales margaret atwoods testament...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns = [\"Category\", \"Content\", \"Content_Parsed_6\"]\n",
    "df = df[list_columns]\n",
    "\n",
    "df = df.rename(columns={'Content_Parsed_6': 'Content_Parsed'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>new york ap  sales margaret atwoods testament...</td>\n",
       "      <td>new york ap  sales margaret atwoods testament...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>minneapolis ap  singer r kelly noshow initial...</td>\n",
       "      <td>minneapolis ap  singer r kelly noshow initial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>soul mate director derek tsang  know ask team...</td>\n",
       "      <td>soul mate director derek tsang  know ask team...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>singapore  voice behind spandau ballet hit tr...</td>\n",
       "      <td>singapore  voice behind spandau ballet hit tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>singapore  south korean heartthrob sing hoon ...</td>\n",
       "      <td>singapore  south korean heartthrob sing hoon ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category                                            Content  \\\n",
       "0  Lifestyle   new york ap  sales margaret atwoods testament...   \n",
       "1  Lifestyle   minneapolis ap  singer r kelly noshow initial...   \n",
       "2  Lifestyle   soul mate director derek tsang  know ask team...   \n",
       "3  Lifestyle   singapore  voice behind spandau ballet hit tr...   \n",
       "4  Lifestyle   singapore  south korean heartthrob sing hoon ...   \n",
       "\n",
       "                                      Content_Parsed  \n",
       "0   new york ap  sales margaret atwoods testament...  \n",
       "1   minneapolis ap  singer r kelly noshow initial...  \n",
       "2   soul mate director derek tsang  know ask team...  \n",
       "3   singapore  voice behind spandau ballet hit tr...  \n",
       "4   singapore  south korean heartthrob sing hoon ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT:**\n",
    "\n",
    "We need to remember that our model will gather the latest news articles from different newspapers every time we want. For that reason, we not only need to take into account the peculiarities of the training set articles, but also possible ones that are present in the gathered news articles.\n",
    "\n",
    "For this reason, possible peculiarities have been studied in the *05. News Scraping* folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Label coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a dictionary with the label codification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_codes = {\n",
    "    'Singapore': 1,\n",
    "    'Sports': 2,\n",
    "    'Lifestyle': 3,\n",
    "    'World': 4,\n",
    "    'Business': 5,\n",
    "    'Technology': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category mapping\n",
    "df['Category_Code'] = df['Category']\n",
    "df = df.replace({'Category_Code':category_codes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Parsed</th>\n",
       "      <th>Category_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>new york ap  sales margaret atwoods testament...</td>\n",
       "      <td>new york ap  sales margaret atwoods testament...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>minneapolis ap  singer r kelly noshow initial...</td>\n",
       "      <td>minneapolis ap  singer r kelly noshow initial...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>soul mate director derek tsang  know ask team...</td>\n",
       "      <td>soul mate director derek tsang  know ask team...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>singapore  voice behind spandau ballet hit tr...</td>\n",
       "      <td>singapore  voice behind spandau ballet hit tr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>singapore  south korean heartthrob sing hoon ...</td>\n",
       "      <td>singapore  south korean heartthrob sing hoon ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category                                            Content  \\\n",
       "0  Lifestyle   new york ap  sales margaret atwoods testament...   \n",
       "1  Lifestyle   minneapolis ap  singer r kelly noshow initial...   \n",
       "2  Lifestyle   soul mate director derek tsang  know ask team...   \n",
       "3  Lifestyle   singapore  voice behind spandau ballet hit tr...   \n",
       "4  Lifestyle   singapore  south korean heartthrob sing hoon ...   \n",
       "\n",
       "                                      Content_Parsed  Category_Code  \n",
       "0   new york ap  sales margaret atwoods testament...              3  \n",
       "1   minneapolis ap  singer r kelly noshow initial...              3  \n",
       "2   soul mate director derek tsang  know ask team...              3  \n",
       "3   singapore  voice behind spandau ballet hit tr...              3  \n",
       "4   singapore  south korean heartthrob sing hoon ...              3  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train - test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll set apart a test set to prove the quality of our models. We'll do Cross Validation in the train set in order to tune the hyperparameters and then test performance on the unseen data of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Content_Parsed'], \n",
    "                                                    df['Category_Code'], \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have much observations (only 2.225), we'll choose a test set size of 15% of the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have various options:\n",
    "\n",
    "* Count Vectors as features\n",
    "* TF-IDF Vectors as features\n",
    "* Word Embeddings as features\n",
    "* Text / NLP based features\n",
    "* Topic Models as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use **TF-IDF Vectors** as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define the different parameters:\n",
    "\n",
    "* `ngram_range`: We want to consider both unigrams and bigrams.\n",
    "* `max_df`: When building the vocabulary ignore terms that have a document\n",
    "    frequency strictly higher than the given threshold\n",
    "* `min_df`: When building the vocabulary ignore terms that have a document\n",
    "    frequency strictly lower than the given threshold.\n",
    "* `max_features`: If not None, build a vocabulary that only consider the top\n",
    "    max_features ordered by term frequency across the corpus.\n",
    "\n",
    "See `TfidfVectorizer?` for further detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It needs to be mentioned that we are implicitly scaling our data when representing it as TF-IDF features with the argument `norm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter election\n",
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have chosen these values as a first approximation. Since the models that we develop later have a very good predictive power, we'll stick to these values. But it has to be mentioned that different combinations could be tried in order to improve even more the accuracy of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9281, 20000)\n",
      "(1638, 20000)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that we have fitted and then transformed the training set, but we have **only transformed** the **test set**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the Chi squared test in order to see what unigrams and bigrams are most correlated with each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'Business' category:\n",
      "  . Most correlated unigrams:\n",
      ". billion\n",
      ". per\n",
      ". cent\n",
      ". trade\n",
      ". tariff\n",
      "  . Most correlated bigrams:\n",
      ". trade pact\n",
      ". per cent\n",
      "\n",
      "# 'Lifestyle' category:\n",
      "  . Most correlated unigrams:\n",
      ". actress\n",
      ". movie\n",
      ". actor\n",
      ". singer\n",
      ". film\n",
      "  . Most correlated bigrams:\n",
      ". post instagram\n",
      ". relate story\n",
      "\n",
      "# 'Singapore' category:\n",
      "  . Most correlated unigrams:\n",
      ". jul\n",
      ". mr\n",
      ". scdf\n",
      ". jail\n",
      ". singapore\n",
      "  . Most correlated bigrams:\n",
      ". singapore civil\n",
      ". years fin\n",
      "\n",
      "# 'Sports' category:\n",
      "  . Most correlated unigrams:\n",
      ". cup\n",
      ". match\n",
      ". win\n",
      ". champion\n",
      ". league\n",
      "  . Most correlated bigrams:\n",
      ". us open\n",
      ". world cup\n",
      "\n",
      "# 'Technology' category:\n",
      "  . Most correlated unigrams:\n",
      ". security\n",
      ". government\n",
      ". protesters\n",
      ". protest\n",
      ". singapore\n",
      "  . Most correlated bigrams:\n",
      ". fire tear\n",
      ". tear gas\n",
      "\n",
      "# 'World' category:\n",
      "  . Most correlated unigrams:\n",
      ". security\n",
      ". government\n",
      ". protesters\n",
      ". protest\n",
      ". singapore\n",
      "  . Most correlated bigrams:\n",
      ". fire tear\n",
      ". tear gas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "\n",
    "for Product, category_id in sorted(category_codes.items()):\n",
    "    features_chi2 = chi2(features_train, labels_train == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}' category:\".format(Product))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-5:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-2:])))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the unigrams correspond well to their category. However, bigrams do not. If we get the bigrams in our features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ongoing trade',\n",
       " 'saturday night',\n",
       " 'cost around',\n",
       " 'foreign investment',\n",
       " 'could add',\n",
       " 'become one',\n",
       " 'macron say',\n",
       " 'nearly per',\n",
       " 'get way',\n",
       " 'also create',\n",
       " 'two others',\n",
       " 'auto part',\n",
       " 'say hear',\n",
       " 'year could',\n",
       " 'post per',\n",
       " 'metoo movement',\n",
       " 'estimate per',\n",
       " 'years also',\n",
       " 'say past',\n",
       " 'time around',\n",
       " 'wear mask',\n",
       " 'two three',\n",
       " 'china india',\n",
       " 'one place',\n",
       " 'rate increase',\n",
       " 'even try',\n",
       " 'hold per',\n",
       " 'year find',\n",
       " 'take months',\n",
       " 'least four',\n",
       " 'want come',\n",
       " 'cultural heritage',\n",
       " 'say remain',\n",
       " 'ask court',\n",
       " 'record us',\n",
       " 'across world',\n",
       " 'stream television',\n",
       " 'almost years',\n",
       " 'end last',\n",
       " 'year accord',\n",
       " 'areas like',\n",
       " 'know whether',\n",
       " 'group include',\n",
       " 'home many',\n",
       " 'like see',\n",
       " 'midautumn festival',\n",
       " 'earlier wednesday',\n",
       " 'good thing',\n",
       " 'british pound',\n",
       " 'pass away',\n",
       " 'plunge per',\n",
       " 'effect climate',\n",
       " 'quarter compare',\n",
       " 'use fund',\n",
       " 'say reason',\n",
       " 'another two',\n",
       " 'quarter say',\n",
       " 'malaysian authorities',\n",
       " 'worth million',\n",
       " 'private sector',\n",
       " 'say want',\n",
       " 'billion worth',\n",
       " 'additional tariff',\n",
       " 'also launch',\n",
       " 'one example',\n",
       " 'compare per',\n",
       " 'less half',\n",
       " 'could come',\n",
       " 'expect us',\n",
       " 'dry weather',\n",
       " 'worlds lead',\n",
       " 'message send',\n",
       " 'home country',\n",
       " 'plan take',\n",
       " 'may last',\n",
       " 'go take',\n",
       " 'growth year',\n",
       " 'rise us',\n",
       " 'court decision',\n",
       " 'go see',\n",
       " 'time family',\n",
       " 'public service',\n",
       " 'google apple',\n",
       " 'phone number',\n",
       " 'economic development',\n",
       " 'investment fund',\n",
       " 'may require',\n",
       " 'recent study',\n",
       " 'take step',\n",
       " 'home without',\n",
       " 'cent rate',\n",
       " 'around globe',\n",
       " 'last see',\n",
       " 'estimate cost',\n",
       " 'revenue billion',\n",
       " 'half us',\n",
       " 'almost three',\n",
       " 'spread across',\n",
       " 'job cut',\n",
       " 'previous year',\n",
       " 'especially come',\n",
       " 'aug first',\n",
       " 'instead use',\n",
       " 'live longer',\n",
       " 'weeks later',\n",
       " 'state oil',\n",
       " 'two decades',\n",
       " 'south american',\n",
       " 'leave us',\n",
       " 'products sell',\n",
       " 'would never',\n",
       " 'shop centre',\n",
       " 'next day',\n",
       " 'point one',\n",
       " 'time say',\n",
       " 'buy property',\n",
       " 'year old',\n",
       " 'standard charter',\n",
       " 'become less',\n",
       " 'edit richard',\n",
       " 'agree buy',\n",
       " 'online retail',\n",
       " 'people make',\n",
       " 'order us',\n",
       " 'things get',\n",
       " 'report josh',\n",
       " 'original content',\n",
       " 'hotel stay',\n",
       " 'technology use',\n",
       " 'also encourage',\n",
       " 'year number',\n",
       " 'home one',\n",
       " 'next five',\n",
       " 'early last',\n",
       " 'also carry',\n",
       " 'take china',\n",
       " 'make official',\n",
       " 'traditional chinese',\n",
       " 'food security',\n",
       " 'add however',\n",
       " 'public private',\n",
       " 'round tariff',\n",
       " 'yearold student',\n",
       " 'financial year',\n",
       " 'billion per',\n",
       " 'new project',\n",
       " 'also suffer',\n",
       " 'play music',\n",
       " 'put place',\n",
       " 'first lady',\n",
       " 'compare year',\n",
       " 'appeal court',\n",
       " 'come years',\n",
       " 'fire say',\n",
       " 'one four',\n",
       " 'end year',\n",
       " 'week later',\n",
       " 'join force',\n",
       " 'bernadette baum',\n",
       " 'charge say',\n",
       " 'say may',\n",
       " 'sport minister',\n",
       " 'least three',\n",
       " 'share company',\n",
       " 'technology also',\n",
       " 'health risk',\n",
       " 'tackle climate',\n",
       " 'younger brother',\n",
       " 'job losses',\n",
       " 'say facebook',\n",
       " 'rat per',\n",
       " 'court appeal',\n",
       " 'say change',\n",
       " 'walk life',\n",
       " 'one seven',\n",
       " 'seek treatment',\n",
       " 'escalate trade',\n",
       " 'hugely popular',\n",
       " 'earlier thursday',\n",
       " 'could also',\n",
       " 'way forward',\n",
       " 'expect make',\n",
       " 'love ones',\n",
       " 'one first',\n",
       " 'bring home',\n",
       " 'also allow',\n",
       " 'management company',\n",
       " 'tariff import',\n",
       " 'service available',\n",
       " 'product gdp',\n",
       " 'show much',\n",
       " 'tv channel',\n",
       " 'follow suit',\n",
       " 'many others',\n",
       " 'make time',\n",
       " 'gas company',\n",
       " 'may lead',\n",
       " 'provide support',\n",
       " 'drink water',\n",
       " 'lead new',\n",
       " 'group chat',\n",
       " 'development minister',\n",
       " 'come year',\n",
       " 'afp reuters',\n",
       " 'year leave',\n",
       " 'remain us',\n",
       " 'continue make',\n",
       " 'would leave',\n",
       " 'second day',\n",
       " 'everyone know',\n",
       " 'might get',\n",
       " 'research find',\n",
       " 'wall streets',\n",
       " 'side road',\n",
       " 'debit card',\n",
       " 'change say',\n",
       " 'ridehailing firm',\n",
       " 'women say',\n",
       " 'decline say',\n",
       " 'first woman',\n",
       " 'company try',\n",
       " 'reduce cost',\n",
       " 'expect announce',\n",
       " 'economy say',\n",
       " 'sumatra kalimantan',\n",
       " 'near future',\n",
       " 'become latest',\n",
       " 'london stock',\n",
       " 'goldman sachs',\n",
       " 'pose risk',\n",
       " 'add government',\n",
       " 'thus far',\n",
       " 'state visit',\n",
       " 'year half',\n",
       " 'west coast',\n",
       " 'market price',\n",
       " 'take away',\n",
       " 'take hospital',\n",
       " 'good reason',\n",
       " 'group people',\n",
       " 'say even',\n",
       " 'cent survey',\n",
       " 'multiple time',\n",
       " 'impose new',\n",
       " 'could make',\n",
       " 'son say',\n",
       " 'technology agency',\n",
       " 'service include',\n",
       " 'previous day',\n",
       " 'group five',\n",
       " 'profit us',\n",
       " 'august year',\n",
       " 'chief operate',\n",
       " 'operate officer',\n",
       " 'may cause',\n",
       " 'environmental protection',\n",
       " 'company board',\n",
       " 'add say',\n",
       " 'market say',\n",
       " 'offer ipo',\n",
       " 'court tuesday',\n",
       " 'cent respondents',\n",
       " 'value chain',\n",
       " 'help reduce',\n",
       " 'ask whether',\n",
       " 'china market',\n",
       " 'give way',\n",
       " 'since september',\n",
       " 'exchange rate',\n",
       " 'get best',\n",
       " 'life imprisonment',\n",
       " 'far east',\n",
       " 'private equity',\n",
       " 'personal computers',\n",
       " 'say third',\n",
       " 'third largest',\n",
       " 'vietnam war',\n",
       " 'world economy',\n",
       " 'saturday morning',\n",
       " 'group also',\n",
       " 'home market',\n",
       " 'may go',\n",
       " 'model would',\n",
       " 'tom brown',\n",
       " 'far less',\n",
       " 'action take',\n",
       " 'statement saturday',\n",
       " 'domestic product',\n",
       " 'compare previous',\n",
       " 'cash flow',\n",
       " 'role play',\n",
       " 'us first',\n",
       " 'chinas commerce',\n",
       " 'work two',\n",
       " 'see us',\n",
       " 'last september',\n",
       " 'take opportunity',\n",
       " 'first place',\n",
       " 'five days',\n",
       " 'grow become',\n",
       " 'raise awareness',\n",
       " 'oil production',\n",
       " 'due start',\n",
       " 'edit louise',\n",
       " 'incident occur',\n",
       " 'make products',\n",
       " 'able make',\n",
       " 'online platform',\n",
       " 'could result',\n",
       " 'yet make',\n",
       " 'make international',\n",
       " 'trade spat',\n",
       " 'come soon',\n",
       " 'may end',\n",
       " 'additional charge',\n",
       " 'tariff chinese',\n",
       " 'might find',\n",
       " 'secondlargest economy',\n",
       " 'would open',\n",
       " 'plan go',\n",
       " 'weibo account',\n",
       " 'get enough',\n",
       " 'additional us',\n",
       " 'japanese food',\n",
       " 'game time',\n",
       " 'say market',\n",
       " 'would cut',\n",
       " 'former chief',\n",
       " 'wong say',\n",
       " 'die hospital',\n",
       " 'around per',\n",
       " 'survey find',\n",
       " 'use plastic',\n",
       " 'fell short',\n",
       " 'abu dhabi',\n",
       " 'publicly available',\n",
       " 'move new',\n",
       " 'half century',\n",
       " 'year still',\n",
       " 'us products',\n",
       " 'likely come',\n",
       " 'level play',\n",
       " 'across asia',\n",
       " 'share close',\n",
       " 'would hit',\n",
       " 'warn sign',\n",
       " 'tell would',\n",
       " 'expect launch',\n",
       " 'company report',\n",
       " 'small amount',\n",
       " 'say enough',\n",
       " 'work one',\n",
       " 'days ago',\n",
       " 'enforcement agencies',\n",
       " 'impossible foods',\n",
       " 'well know',\n",
       " 'early trade',\n",
       " 'make much',\n",
       " 'least us',\n",
       " 'use personal',\n",
       " 'three five',\n",
       " 'wednesday may',\n",
       " 'case relate',\n",
       " 'net loss',\n",
       " 'social workers',\n",
       " 'last seven',\n",
       " 'least per',\n",
       " 'say former',\n",
       " 'sentence years',\n",
       " 'mental health',\n",
       " 'part world',\n",
       " 'global supply',\n",
       " 'quality life',\n",
       " 'reduce risk',\n",
       " 'year three',\n",
       " 'key part',\n",
       " 'publish journal',\n",
       " 'men women',\n",
       " 'international financial',\n",
       " 'fail comply',\n",
       " 'steve job',\n",
       " 'call one',\n",
       " 'heart rate',\n",
       " 'deal also',\n",
       " 'three main',\n",
       " 'one know',\n",
       " 'per dollar',\n",
       " 'beef pork',\n",
       " 'also mean',\n",
       " 'turn point',\n",
       " 'say currently',\n",
       " 'second time',\n",
       " 'asian country',\n",
       " 'stay away',\n",
       " 'past years',\n",
       " 'refinitiv data',\n",
       " 'run away',\n",
       " 'even dont',\n",
       " 'edit saumyadeb',\n",
       " 'ways make',\n",
       " 'also write',\n",
       " 'team take',\n",
       " 'area say',\n",
       " 'turn away',\n",
       " 'state canada',\n",
       " 'cent tariff',\n",
       " 'commit suicide',\n",
       " 'early stag',\n",
       " 'set take',\n",
       " 'later say',\n",
       " 'information communications',\n",
       " 'saudi arabia',\n",
       " 'set stage',\n",
       " 'thursday company',\n",
       " 'malaysia indonesia',\n",
       " 'johor bahru',\n",
       " 'consumer goods',\n",
       " 'increase tariff',\n",
       " 'since july',\n",
       " 'announce tuesday',\n",
       " 'statement add',\n",
       " 'louise heavens',\n",
       " 'think need',\n",
       " 'enough make',\n",
       " 'set back',\n",
       " 'traffic light',\n",
       " 'impose per',\n",
       " 'chief executives',\n",
       " 'say let',\n",
       " 'state court',\n",
       " 'things say',\n",
       " 'younger sister',\n",
       " 'need keep',\n",
       " 'minister office',\n",
       " 'case report',\n",
       " 'people dont',\n",
       " 'across unite',\n",
       " 'people turn',\n",
       " 'blood pressure',\n",
       " 'auto industry',\n",
       " 'far cry',\n",
       " 'areas include',\n",
       " 'also introduce',\n",
       " 'yang say',\n",
       " 'set aside',\n",
       " 'time people',\n",
       " 'better understand',\n",
       " 'leave behind',\n",
       " 'think twice',\n",
       " 'wide variety',\n",
       " 'cent share',\n",
       " 'assistant professor',\n",
       " 'vice premier',\n",
       " 'industry source',\n",
       " 'make one',\n",
       " 'milk tea',\n",
       " 'remain see',\n",
       " 'like take',\n",
       " 'lorry driver',\n",
       " 'affect us',\n",
       " 'release us',\n",
       " 'tuesday july',\n",
       " 'worth chinese',\n",
       " 'big bang',\n",
       " 'would result',\n",
       " 'may give',\n",
       " 'carbon dioxide',\n",
       " 'new round',\n",
       " 'record show',\n",
       " 'take years',\n",
       " 'july august',\n",
       " 'would difficult',\n",
       " 'less year',\n",
       " 'make several',\n",
       " 'use data',\n",
       " 'add people',\n",
       " 'home make',\n",
       " 'come us',\n",
       " 'large amount',\n",
       " 'may look',\n",
       " 'however still',\n",
       " 'begin last',\n",
       " 'us soybeans',\n",
       " 'show one',\n",
       " 'period year',\n",
       " 'people age',\n",
       " 'statement yesterday',\n",
       " 'early next',\n",
       " 'say help',\n",
       " 'breach trust',\n",
       " 'say family',\n",
       " 'south korean',\n",
       " 'add us',\n",
       " 'company list',\n",
       " 'sell products',\n",
       " 'watch videos',\n",
       " 'want make',\n",
       " 'hotspots detect',\n",
       " 'industry players',\n",
       " 'labour force',\n",
       " 'return work',\n",
       " 'haze situation',\n",
       " 'st engineer',\n",
       " 'become popular',\n",
       " 'sum money',\n",
       " 'gross domestic',\n",
       " 'invest us',\n",
       " 'send message',\n",
       " 'last minute',\n",
       " 'way back',\n",
       " 'right say',\n",
       " 'follow two',\n",
       " 'mnuchin say',\n",
       " 'also conduct',\n",
       " 'better job',\n",
       " 'july say',\n",
       " 'us dollar',\n",
       " 'vow take',\n",
       " 'real world',\n",
       " 'end trade',\n",
       " 'allow take',\n",
       " 'fair share',\n",
       " 'family say',\n",
       " 'worth billion',\n",
       " 'grace period',\n",
       " 'say agency',\n",
       " 'east coast',\n",
       " 'earn call',\n",
       " 'deal say',\n",
       " 'good chance',\n",
       " 'escalation trade',\n",
       " 'say important',\n",
       " 'market fear',\n",
       " 'receive million',\n",
       " 'less three',\n",
       " 'within three',\n",
       " 'tell us',\n",
       " 'say allegations',\n",
       " 'main reason',\n",
       " 'suffer serious',\n",
       " 'also possible',\n",
       " 'get home',\n",
       " 'less per',\n",
       " 'saturday even',\n",
       " 'body part',\n",
       " 'view million',\n",
       " 'amazon prime',\n",
       " 'people would',\n",
       " 'one reason',\n",
       " 'new service',\n",
       " 'sport utility',\n",
       " 'also continue',\n",
       " 'would make',\n",
       " 'million view',\n",
       " 'wont able',\n",
       " 'police department',\n",
       " 'age two',\n",
       " 'consumer electronics',\n",
       " 'take money',\n",
       " 'year include',\n",
       " 'time see',\n",
       " 'cold water',\n",
       " 'company set',\n",
       " 'war washington',\n",
       " 'level singapore',\n",
       " 'also add',\n",
       " 'get us',\n",
       " 'grab say',\n",
       " 'firm say',\n",
       " 'able take',\n",
       " 'another us',\n",
       " 'see take',\n",
       " 'last november',\n",
       " 'outdoor activities',\n",
       " 'source close',\n",
       " 'aim bring',\n",
       " 'people walk',\n",
       " 'million per',\n",
       " 'well provide',\n",
       " 'ipod touch',\n",
       " 'china per',\n",
       " 'loss us',\n",
       " 'would consider',\n",
       " 'come effect',\n",
       " 'photos take',\n",
       " 'tensions unite',\n",
       " 'number two',\n",
       " 'new measure',\n",
       " 'meet say',\n",
       " 'right direction',\n",
       " 'would raise',\n",
       " 'wear black',\n",
       " 'amount money',\n",
       " 'high speed',\n",
       " 'make easy',\n",
       " 'also man',\n",
       " 'report stephen',\n",
       " 'service could',\n",
       " 'important us',\n",
       " 'could happen',\n",
       " 'say go',\n",
       " 'expect see',\n",
       " 'return home',\n",
       " 'must make',\n",
       " 'say prosecutors',\n",
       " 'come months',\n",
       " 'decade ago',\n",
       " 'move around',\n",
       " 'time soon',\n",
       " 'want live',\n",
       " 'find way',\n",
       " 'shop malls',\n",
       " 'flight hong',\n",
       " 'work well',\n",
       " 'say also',\n",
       " 'shailesh kuber',\n",
       " 'much less',\n",
       " 'service help',\n",
       " 'solar panel',\n",
       " 'waste time',\n",
       " 'get work',\n",
       " 'would still',\n",
       " 'add think',\n",
       " 'late june',\n",
       " 'people one',\n",
       " 'right next',\n",
       " 'could consider',\n",
       " 'accord refinitiv',\n",
       " 'post video',\n",
       " 'closer home',\n",
       " 'listen music',\n",
       " 'fall apart',\n",
       " 'open public',\n",
       " 'us goods',\n",
       " 'almost double',\n",
       " 'company look',\n",
       " 'cut cost',\n",
       " 'forecast per',\n",
       " 'local market',\n",
       " 'leave side',\n",
       " 'represent per',\n",
       " 'three quarter',\n",
       " 'still face',\n",
       " 'hit unhealthy',\n",
       " 'court thursday',\n",
       " 'time write',\n",
       " 'sell online',\n",
       " 'popular among',\n",
       " 'motor co',\n",
       " 'oil company',\n",
       " 'hours week',\n",
       " 'start look',\n",
       " 'fell apart',\n",
       " 'sunday time',\n",
       " 'week also',\n",
       " 'tariff per',\n",
       " 'become biggest',\n",
       " 'products say',\n",
       " 'world make',\n",
       " 'barrel per',\n",
       " 'different ways',\n",
       " 'average per',\n",
       " 'offer discount',\n",
       " 'best thing',\n",
       " 'latest round',\n",
       " 'higher price',\n",
       " 'say put',\n",
       " 'impact climate',\n",
       " 'say best',\n",
       " 'water bottle',\n",
       " 'monday aug',\n",
       " 'say follow',\n",
       " 'court say',\n",
       " 'try make',\n",
       " 'expect reach',\n",
       " 'would look',\n",
       " 'use make',\n",
       " 'years accord',\n",
       " 'could bring',\n",
       " 'city say',\n",
       " 'open door',\n",
       " 'visit philippines',\n",
       " 'say much',\n",
       " 'closely monitor',\n",
       " 'tuesday sept',\n",
       " 'research show',\n",
       " 'action would',\n",
       " 'would come',\n",
       " 'keep fight',\n",
       " 'us tariff',\n",
       " 'address concern',\n",
       " 'million investment',\n",
       " 'work company',\n",
       " 'pacific nations',\n",
       " 'look great',\n",
       " 'allow customers',\n",
       " 'issue also',\n",
       " 'corp say',\n",
       " 'situation say',\n",
       " 'per month',\n",
       " 'able see',\n",
       " 'user experience',\n",
       " 'online show',\n",
       " 'nearly years',\n",
       " 'us import',\n",
       " 'edit tom',\n",
       " 'place us',\n",
       " 'say felt',\n",
       " 'cut job',\n",
       " 'sunday aug',\n",
       " 'release last',\n",
       " 'study publish',\n",
       " 'want help',\n",
       " 'also step',\n",
       " 'significant amount',\n",
       " 'comment make',\n",
       " 'insurance policy',\n",
       " 'videos post',\n",
       " 'say reuters',\n",
       " 'available online',\n",
       " 'accord company',\n",
       " 'country also',\n",
       " 'one use',\n",
       " 'flow traffic',\n",
       " 'bring together',\n",
       " 'go beyond',\n",
       " 'per us',\n",
       " 'young girl',\n",
       " 'important part',\n",
       " 'never see',\n",
       " 'week say',\n",
       " 'hk million',\n",
       " 'impact trade',\n",
       " 'take back',\n",
       " 'would prefer',\n",
       " 'exhibition centre',\n",
       " 'domestic violence',\n",
       " 'fiscal year',\n",
       " 'million barrel',\n",
       " 'new digital',\n",
       " 'company go',\n",
       " 'share photos',\n",
       " 'agricultural products',\n",
       " 'worlds top',\n",
       " 'us would',\n",
       " 'also present',\n",
       " 'account use',\n",
       " 'rock star',\n",
       " 'also tell',\n",
       " 'sea level',\n",
       " 'also singapore',\n",
       " 'thailand vietnam',\n",
       " 'also order',\n",
       " 'would tell',\n",
       " 'since find',\n",
       " 'post monday',\n",
       " 'also lead',\n",
       " 'sep dec',\n",
       " 'already work',\n",
       " 'begin impose',\n",
       " 'previously say',\n",
       " 'allow us',\n",
       " 'also leave',\n",
       " 'per capita',\n",
       " 'know work',\n",
       " 'school also',\n",
       " 'news come',\n",
       " 'highest number',\n",
       " 'far away',\n",
       " 'latin americas',\n",
       " 'resolve issue',\n",
       " 'weather condition',\n",
       " 'perform well',\n",
       " 'next decade',\n",
       " 'business class',\n",
       " 'every year',\n",
       " 'around world',\n",
       " 'say include',\n",
       " 'japan softbank',\n",
       " 'whats happen',\n",
       " 'make payments',\n",
       " 'type diabetes',\n",
       " 'two children',\n",
       " 'try take',\n",
       " 'high us',\n",
       " 'already know',\n",
       " 'company seek',\n",
       " 'earlier year',\n",
       " 'technical education',\n",
       " 'law order',\n",
       " 'also involve',\n",
       " 'people like',\n",
       " 'report suggest',\n",
       " 'say concern',\n",
       " 'tuesday say',\n",
       " 'cant afford',\n",
       " 'continue grow',\n",
       " 'change make',\n",
       " 'one count',\n",
       " 'data also',\n",
       " 'chan say',\n",
       " 'mean take',\n",
       " 'say base',\n",
       " 'people want',\n",
       " 'cause fire',\n",
       " 'many new',\n",
       " 'million us',\n",
       " 'say surprise',\n",
       " 'second floor',\n",
       " 'huge amount',\n",
       " 'try best',\n",
       " 'wakeup call',\n",
       " 'singleuse plastics',\n",
       " 'use pay',\n",
       " 'hong kongbased',\n",
       " 'last meet',\n",
       " 'three men',\n",
       " 'saudi arabias',\n",
       " 'plan us',\n",
       " 'sugar level',\n",
       " 'sector say',\n",
       " 'post also',\n",
       " 'even go',\n",
       " 'lower risk',\n",
       " 'side would',\n",
       " 'josh horwitz',\n",
       " 'cent august',\n",
       " 'general motor',\n",
       " 'beijing washington',\n",
       " 'electricity bill',\n",
       " 'get access',\n",
       " 'name new',\n",
       " 'start play',\n",
       " 'lose control',\n",
       " 'build new',\n",
       " 'compare million',\n",
       " 'subscription service',\n",
       " 'say several',\n",
       " 'far year',\n",
       " 'trade war',\n",
       " 'build house',\n",
       " 'hop see',\n",
       " 'bloomberg news',\n",
       " 'smoke inhalation',\n",
       " 'say something',\n",
       " 'age population',\n",
       " 'fiat chrysler',\n",
       " 'test positive',\n",
       " 'come light',\n",
       " 'baby bear',\n",
       " 'past months',\n",
       " 'plan invest',\n",
       " 'nissan motor',\n",
       " 'week us',\n",
       " 'new challenge',\n",
       " 'biarritz france',\n",
       " 'post social',\n",
       " 'one hour',\n",
       " 'export us',\n",
       " 'penal code',\n",
       " 'feature include',\n",
       " 'human capital',\n",
       " 'thursday night',\n",
       " 'month first',\n",
       " 'go online',\n",
       " 'throughout day',\n",
       " 'provide access',\n",
       " 'company could',\n",
       " 'know many',\n",
       " 'store also',\n",
       " 'within two',\n",
       " 'could find',\n",
       " 'billion company',\n",
       " 'sweep change',\n",
       " 'tariff war',\n",
       " 'year however',\n",
       " 'right away',\n",
       " 'also start',\n",
       " 'trade relations',\n",
       " 'end july',\n",
       " 'situation get',\n",
       " 'also meet',\n",
       " 'start work',\n",
       " 'say investigate',\n",
       " 'market expectations',\n",
       " 'oil market',\n",
       " 'private property',\n",
       " 'would put',\n",
       " 'also issue',\n",
       " 'month would',\n",
       " 'company announce',\n",
       " 'also buy',\n",
       " 'last sunday',\n",
       " 'youll get',\n",
       " 'aug police',\n",
       " 'able find',\n",
       " 'action say',\n",
       " 'state europe',\n",
       " 'environmental impact',\n",
       " 'director say',\n",
       " 'take photos',\n",
       " 'way say',\n",
       " 'corporate casualty',\n",
       " 'would good',\n",
       " 'also highlight',\n",
       " 'people see',\n",
       " 'key role',\n",
       " 'five million',\n",
       " 'among people',\n",
       " 'years company',\n",
       " 'two suspect',\n",
       " 'show people',\n",
       " 'pm singapore',\n",
       " 'join company',\n",
       " 'bubble tea',\n",
       " 'get things',\n",
       " 'end may',\n",
       " 'shop platform',\n",
       " 'justice system',\n",
       " 'also arrest',\n",
       " 'say spokesman',\n",
       " 'total million',\n",
       " 'late night',\n",
       " 'work make',\n",
       " 'feel comfortable',\n",
       " 'community service',\n",
       " 'bloomberg report',\n",
       " 'joint statement',\n",
       " 'meet need',\n",
       " 'drop per',\n",
       " 'traders say',\n",
       " 'lot things',\n",
       " 'dark side',\n",
       " 'agree pay',\n",
       " 'propose change',\n",
       " 'say research',\n",
       " 'construction work',\n",
       " 'dont see',\n",
       " 'accord court',\n",
       " 'supply chain',\n",
       " 'monday night',\n",
       " 'come pressure',\n",
       " 'would probably',\n",
       " 'spend two',\n",
       " 'also apply',\n",
       " 'remain unchanged',\n",
       " 'authority say',\n",
       " 'chat group',\n",
       " 'help bring',\n",
       " 'sexually assault',\n",
       " 'analysts estimate',\n",
       " 'slow growth',\n",
       " 'wide range',\n",
       " 'roughly us',\n",
       " 'plan tariff',\n",
       " 'number us',\n",
       " 'tell journalists',\n",
       " 'total us',\n",
       " 'past six',\n",
       " 'business school',\n",
       " 'would stop',\n",
       " 'company may',\n",
       " 'global oil',\n",
       " 'one three',\n",
       " 'dont go',\n",
       " 'estimate us',\n",
       " 'come forward',\n",
       " 'capital control',\n",
       " 'wait time',\n",
       " 'hold back',\n",
       " 'go school',\n",
       " 'say part',\n",
       " 'bin salman',\n",
       " 'day later',\n",
       " 'also want',\n",
       " 'weeks ago',\n",
       " 'make plan',\n",
       " 'six weeks',\n",
       " 'money would',\n",
       " 'singapores national',\n",
       " 'northern ireland',\n",
       " 'accord people',\n",
       " 'higher level',\n",
       " 'would receive',\n",
       " 'say response',\n",
       " 'organisers say',\n",
       " 'credit rat',\n",
       " 'need work',\n",
       " 'want find',\n",
       " 'share us',\n",
       " 'officer also',\n",
       " 'take effect',\n",
       " 'goods include',\n",
       " 'game world',\n",
       " 'post say',\n",
       " 'go ahead',\n",
       " 'sexual harassment',\n",
       " 'want return',\n",
       " 'get around',\n",
       " 'thursday july',\n",
       " ...]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are only six. This means the unigrams have more correlation with the category than the bigrams, and since we're restricting the number of features to the most representative 300, only a few bigrams are being considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the files we'll need in the next steps:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
